{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "# Librerías básicas\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import settings as sts\n",
    "\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models import Phrases\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Paquetes del proyecto\n",
    "from modules.etl.conexiones import Conexion\n",
    "from modules.etl.etl_secop import *\n",
    "from modules.etl.etl_dane_pob import *\n",
    "from modules.etl.etl_dane_ipm import *\n",
    "from modules.modelos.lda  import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.10:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[12]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>my_app</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2251b7a6700>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conexion a Spark\n",
    "\n",
    "# Crear una instancia de la clase Conexion\n",
    "conexion = Conexion()\n",
    "conexion.init_spark_session()\n",
    "spark_session = conexion.spark_session\n",
    "spark_session.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # para generar mejor formato de tablas\n",
    "spark_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar base de datos SECOP I en Spark DataFrame\n",
    "df_secop_crudo = spark_session.read.csv(sts.crudos+'SECOP.csv', header=True, schema = sts.schema_secop)\n",
    "# Cargar información DANE y equivalencia del Departamento con SECOP\n",
    "df_dpto_reg = spark_session.read.option(\"delimiter\", \";\").option(\"header\", True).csv(sts.crudos+\"Regiones_Departamentos.csv\")\n",
    "# Se carga el archivo csv con los datos de los contratos\n",
    "datos = pd.read_csv(sts.datamart+'df_secop_obra.csv', encoding='utf-8', low_memory=False)\n",
    "pobl_2010_2019 = pd.read_excel(sts.crudos+'DCD-area-proypoblacion-dep-2005-2019.xlsx')\n",
    "pobl_2020_2030 = pd.read_excel(sts.crudos+'DCD-area-proypoblacion-dep-2020-2050-ActPostCOVID-19.xlsx')\n",
    "ipm_departamentos = pd.read_excel(sts.crudos+\"anexo_dptal_pobreza_multidimensional_21.xls\", sheet_name=sts.hojas[1], skiprows=range(14), nrows=33)\n",
    "ipm_regiones = pd.read_excel(sts.crudos+\"anexo_dptal_pobreza_multidimensional_21.xls\", sheet_name=sts.hojas[2], skiprows=range(14), nrows=9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error to set the ticket\n",
      "<class 'ValueError'>\n",
      "too many values to unpack (expected 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Jelb7\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk size:  1000\n",
      "Optimal number of topics:  7\n",
      "Optimal alpha:  0.38\n",
      "Optimal eta:  0.65\n"
     ]
    }
   ],
   "source": [
    "# Intanciando Clases\n",
    "etl=SECOP_ETL(spark_session)\n",
    "poblacion_dane = PoblacionDANE(pobl_2010_2019, pobl_2020_2030)\n",
    "ipm=IPM_DANE()\n",
    "\n",
    "# Constructor\n",
    "if __name__=='__main__':\n",
    "    etl.cargar_df_secop(etl,df_secop_crudo,sts.columnas_drop,df_dpto_reg,sts.old_new_names_dict,sts.cols_integer,sts.cols_date,sts.cols_str,sts.cols_money)\n",
    "    spark_session.stop()\n",
    "    poblacion_dane.poblacion(poblacion_dane,pobl_2010_2019,pobl_2020_2030)\n",
    "    ipm.procesar_datos_ipm(ipm,sts.ruta_archivo_21, sts.ruta_archivo2, \n",
    "                           sts.crudos,ipm_departamentos,sts.columnas, sts.tipos, sts.anios,\n",
    "                           ipm_regiones, sts.Area_dicc, sts.Region_dict, \n",
    "                           sts.region_dict, sts.hojas[4], sts.skiprows_dict, sts.nrows_dict,sts.hojas[5],\n",
    "                           sts.Area_dicc_zona, sts.hojas[6], sts.skiprows_dict1, sts.hojas[7], \n",
    "                           sts.skiprows_dict2, sts.anios2, sts.Area_dicc1, sts.skiprows_dict3,sts.departamentos_tupla1)\n",
    "    execute_analysis(datos)\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
